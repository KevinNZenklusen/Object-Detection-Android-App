{"cells":[{"cell_type":"code","execution_count":2,"id":"6636fe0f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69769,"status":"ok","timestamp":1722791793265,"user":{"displayName":"Kevin Zenklusen","userId":"03417330047758242723"},"user_tz":180},"id":"6636fe0f","outputId":"4ad3e333-46d4-4a71-8283-bd0f46a28ad5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.74-py3-none-any.whl.metadata (41 kB)\n","Collecting numpy<2.0.0,>=1.23.0 (from ultralytics)\n","  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n","Collecting matplotlib>=3.3.0 (from ultralytics)\n","  Downloading matplotlib-3.9.1.post1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n","Collecting opencv-python>=4.6.0 (from ultralytics)\n","  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n","Collecting pillow>=7.1.2 (from ultralytics)\n","  Downloading pillow-10.4.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)\n","Collecting pyyaml>=5.3.1 (from ultralytics)\n","  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n","Collecting requests>=2.23.0 (from ultralytics)\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting scipy>=1.4.1 (from ultralytics)\n","  Downloading scipy-1.14.0-cp310-cp310-win_amd64.whl.metadata (60 kB)\n","Collecting torch>=1.8.0 (from ultralytics)\n","  Downloading torch-2.4.0-cp310-cp310-win_amd64.whl.metadata (27 kB)\n","Collecting torchvision>=0.9.0 (from ultralytics)\n","  Downloading torchvision-0.19.0-1-cp310-cp310-win_amd64.whl.metadata (6.1 kB)\n","Collecting tqdm>=4.64.0 (from ultralytics)\n","  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n","Requirement already satisfied: psutil in c:\\users\\kev9n\\onedrive\\documentos\\tv-screen-object-detection\\.venv\\lib\\site-packages (from ultralytics) (6.0.0)\n","Collecting py-cpuinfo (from ultralytics)\n","  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n","Collecting pandas>=1.1.4 (from ultralytics)\n","  Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n","Collecting seaborn>=0.11.0 (from ultralytics)\n","  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Using cached ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\n","  Downloading contourpy-1.2.1-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n","Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\n","  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\n","  Downloading fonttools-4.53.1-cp310-cp310-win_amd64.whl.metadata (165 kB)\n","Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\n","  Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\kev9n\\onedrive\\documentos\\tv-screen-object-detection\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics)\n","  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kev9n\\onedrive\\documentos\\tv-screen-object-detection\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\n","  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n","  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting charset-normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n","  Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl.metadata (34 kB)\n","Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n","  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n","  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n","Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n","  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n","Collecting filelock (from torch>=1.8.0->ultralytics)\n","  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kev9n\\onedrive\\documentos\\tv-screen-object-detection\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Collecting sympy (from torch>=1.8.0->ultralytics)\n","  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch>=1.8.0->ultralytics)\n","  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n","Collecting jinja2 (from torch>=1.8.0->ultralytics)\n","  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n","Collecting fsspec (from torch>=1.8.0->ultralytics)\n","  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: colorama in c:\\users\\kev9n\\onedrive\\documentos\\tv-screen-object-detection\\.venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n","Requirement already satisfied: six>=1.5 in c:\\users\\kev9n\\onedrive\\documentos\\tv-screen-object-detection\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.8.0->ultralytics)\n","  Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n","Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.8.0->ultralytics)\n","  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Downloading ultralytics-8.2.74-py3-none-any.whl (865 kB)\n","   ---------------------------------------- 0.0/865.5 kB ? eta -:--:--\n","   ---------------------------------------- 865.5/865.5 kB 4.8 MB/s eta 0:00:00\n","Downloading matplotlib-3.9.1.post1-cp310-cp310-win_amd64.whl (8.0 MB)\n","   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n","   ---------- ----------------------------- 2.1/8.0 MB 10.7 MB/s eta 0:00:01\n","   ----------------------- ---------------- 4.7/8.0 MB 11.9 MB/s eta 0:00:01\n","   ------------------------------------ --- 7.3/8.0 MB 12.2 MB/s eta 0:00:01\n","   ---------------------------------------- 8.0/8.0 MB 12.0 MB/s eta 0:00:00\n","Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n","   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n","   ------ --------------------------------- 2.6/15.8 MB 12.6 MB/s eta 0:00:02\n","   ------------- -------------------------- 5.2/15.8 MB 13.3 MB/s eta 0:00:01\n","   ------------------- -------------------- 7.9/15.8 MB 13.2 MB/s eta 0:00:01\n","   -------------------------- ------------- 10.5/15.8 MB 12.8 MB/s eta 0:00:01\n","   --------------------------------- ------ 13.4/15.8 MB 12.9 MB/s eta 0:00:01\n","   ---------------------------------------- 15.8/15.8 MB 12.6 MB/s eta 0:00:00\n","Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n","Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl (11.6 MB)\n","   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n","   --------- ------------------------------ 2.6/11.6 MB 12.6 MB/s eta 0:00:01\n","   ------------------ --------------------- 5.2/11.6 MB 12.8 MB/s eta 0:00:01\n","   --------------------------- ------------ 7.9/11.6 MB 12.5 MB/s eta 0:00:01\n","   ------------------------------------ --- 10.5/11.6 MB 12.8 MB/s eta 0:00:01\n","   ---------------------------------------- 11.6/11.6 MB 12.5 MB/s eta 0:00:00\n","Downloading pillow-10.4.0-cp310-cp310-win_amd64.whl (2.6 MB)\n","   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n","   ---------------------------------------- 2.6/2.6 MB 12.2 MB/s eta 0:00:00\n","Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n","Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Downloading scipy-1.14.0-cp310-cp310-win_amd64.whl (44.8 MB)\n","   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n","   -- ------------------------------------- 2.6/44.8 MB 12.6 MB/s eta 0:00:04\n","   ---- ----------------------------------- 5.2/44.8 MB 12.7 MB/s eta 0:00:04\n","   ------- -------------------------------- 7.9/44.8 MB 12.8 MB/s eta 0:00:03\n","   --------- ------------------------------ 10.5/44.8 MB 12.8 MB/s eta 0:00:03\n","   ----------- ---------------------------- 12.3/44.8 MB 12.9 MB/s eta 0:00:03\n","   -------------- ------------------------- 16.0/44.8 MB 12.9 MB/s eta 0:00:03\n","   ---------------- ----------------------- 18.6/44.8 MB 12.8 MB/s eta 0:00:03\n","   ------------------- -------------------- 21.5/44.8 MB 12.8 MB/s eta 0:00:02\n","   --------------------- ------------------ 24.1/44.8 MB 12.8 MB/s eta 0:00:02\n","   ----------------------- ---------------- 26.7/44.8 MB 12.9 MB/s eta 0:00:02\n","   ------------------------ --------------- 27.8/44.8 MB 12.9 MB/s eta 0:00:02\n","   ---------------------------- ----------- 32.2/44.8 MB 12.9 MB/s eta 0:00:01\n","   ------------------------------- -------- 34.9/44.8 MB 12.9 MB/s eta 0:00:01\n","   --------------------------------- ------ 37.5/44.8 MB 12.8 MB/s eta 0:00:01\n","   ----------------------------------- ---- 40.1/44.8 MB 12.9 MB/s eta 0:00:01\n","   -------------------------------------- - 42.7/44.8 MB 12.8 MB/s eta 0:00:01\n","   ---------------------------------------- 44.8/44.8 MB 12.7 MB/s eta 0:00:00\n","Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n","Downloading torch-2.4.0-cp310-cp310-win_amd64.whl (197.9 MB)\n","   ---------------------------------------- 0.0/197.9 MB ? eta -:--:--\n","    --------------------------------------- 2.6/197.9 MB 13.7 MB/s eta 0:00:15\n","   - -------------------------------------- 5.5/197.9 MB 13.4 MB/s eta 0:00:15\n","   - -------------------------------------- 8.1/197.9 MB 12.9 MB/s eta 0:00:15\n","   -- ------------------------------------- 10.7/197.9 MB 12.9 MB/s eta 0:00:15\n","   -- ------------------------------------- 13.4/197.9 MB 12.9 MB/s eta 0:00:15\n","   --- ------------------------------------ 16.3/197.9 MB 13.1 MB/s eta 0:00:14\n","   --- ------------------------------------ 18.9/197.9 MB 13.1 MB/s eta 0:00:14\n","   ---- ----------------------------------- 21.5/197.9 MB 12.9 MB/s eta 0:00:14\n","   ---- ----------------------------------- 24.1/197.9 MB 12.9 MB/s eta 0:00:14\n","   ----- ---------------------------------- 27.0/197.9 MB 13.0 MB/s eta 0:00:14\n","   ----- ---------------------------------- 29.6/197.9 MB 13.0 MB/s eta 0:00:13\n","   ------ --------------------------------- 32.2/197.9 MB 12.9 MB/s eta 0:00:13\n","   ------- -------------------------------- 35.1/197.9 MB 13.0 MB/s eta 0:00:13\n","   ------- -------------------------------- 37.7/197.9 MB 13.0 MB/s eta 0:00:13\n","   -------- ------------------------------- 40.6/197.9 MB 13.0 MB/s eta 0:00:13\n","   -------- ------------------------------- 43.0/197.9 MB 13.0 MB/s eta 0:00:12\n","   --------- ------------------------------ 45.9/197.9 MB 12.9 MB/s eta 0:00:12\n","   --------- ------------------------------ 48.5/197.9 MB 12.9 MB/s eta 0:00:12\n","   ---------- ----------------------------- 51.1/197.9 MB 12.9 MB/s eta 0:00:12\n","   ---------- ----------------------------- 54.0/197.9 MB 13.0 MB/s eta 0:00:12\n","   ----------- ---------------------------- 56.6/197.9 MB 12.9 MB/s eta 0:00:11\n","   ----------- ---------------------------- 59.2/197.9 MB 12.9 MB/s eta 0:00:11\n","   ------------ --------------------------- 62.1/197.9 MB 12.9 MB/s eta 0:00:11\n","   ------------- -------------------------- 64.7/197.9 MB 12.9 MB/s eta 0:00:11\n","   ------------- -------------------------- 67.4/197.9 MB 12.9 MB/s eta 0:00:11\n","   -------------- ------------------------- 70.3/197.9 MB 12.9 MB/s eta 0:00:10\n","   -------------- ------------------------- 72.9/197.9 MB 12.9 MB/s eta 0:00:10\n","   --------------- ------------------------ 75.5/197.9 MB 12.9 MB/s eta 0:00:10\n","   --------------- ------------------------ 78.4/197.9 MB 12.9 MB/s eta 0:00:10\n","   ---------------- ----------------------- 81.3/197.9 MB 12.9 MB/s eta 0:00:10\n","   ---------------- ----------------------- 83.9/197.9 MB 12.9 MB/s eta 0:00:09\n","   ----------------- ---------------------- 86.5/197.9 MB 12.9 MB/s eta 0:00:09\n","   ------------------ --------------------- 89.4/197.9 MB 12.9 MB/s eta 0:00:09\n","   ------------------ --------------------- 92.0/197.9 MB 12.9 MB/s eta 0:00:09\n","   ------------------- -------------------- 94.6/197.9 MB 12.9 MB/s eta 0:00:08\n","   ------------------- -------------------- 97.3/197.9 MB 12.9 MB/s eta 0:00:08\n","   ------------------- ------------------- 100.1/197.9 MB 12.9 MB/s eta 0:00:08\n","   -------------------- ------------------ 102.8/197.9 MB 12.9 MB/s eta 0:00:08\n","   -------------------- ------------------ 105.4/197.9 MB 12.9 MB/s eta 0:00:08\n","   --------------------- ----------------- 108.0/197.9 MB 12.9 MB/s eta 0:00:07\n","   --------------------- ----------------- 110.9/197.9 MB 12.9 MB/s eta 0:00:07\n","   ---------------------- ---------------- 113.5/197.9 MB 12.9 MB/s eta 0:00:07\n","   ---------------------- ---------------- 116.1/197.9 MB 12.9 MB/s eta 0:00:07\n","   ----------------------- --------------- 119.0/197.9 MB 12.9 MB/s eta 0:00:07\n","   ----------------------- --------------- 121.4/197.9 MB 12.9 MB/s eta 0:00:06\n","   ------------------------ -------------- 124.3/197.9 MB 12.9 MB/s eta 0:00:06\n","   ------------------------- ------------- 126.9/197.9 MB 12.9 MB/s eta 0:00:06\n","   ------------------------- ------------- 129.8/197.9 MB 12.9 MB/s eta 0:00:06\n","   -------------------------- ------------ 132.4/197.9 MB 12.9 MB/s eta 0:00:06\n","   -------------------------- ------------ 135.3/197.9 MB 12.9 MB/s eta 0:00:05\n","   --------------------------- ----------- 137.9/197.9 MB 12.9 MB/s eta 0:00:05\n","   --------------------------- ----------- 140.8/197.9 MB 12.9 MB/s eta 0:00:05\n","   ---------------------------- ---------- 143.1/197.9 MB 12.9 MB/s eta 0:00:05\n","   ---------------------------- ---------- 146.0/197.9 MB 12.9 MB/s eta 0:00:05\n","   ----------------------------- --------- 148.6/197.9 MB 12.9 MB/s eta 0:00:04\n","   ----------------------------- --------- 151.5/197.9 MB 12.9 MB/s eta 0:00:04\n","   ------------------------------ -------- 153.9/197.9 MB 12.9 MB/s eta 0:00:04\n","   ------------------------------ -------- 156.8/197.9 MB 12.9 MB/s eta 0:00:04\n","   ------------------------------- ------- 159.4/197.9 MB 12.9 MB/s eta 0:00:03\n","   ------------------------------- ------- 162.3/197.9 MB 12.9 MB/s eta 0:00:03\n","   -------------------------------- ------ 164.6/197.9 MB 12.9 MB/s eta 0:00:03\n","   --------------------------------- ----- 167.5/197.9 MB 12.9 MB/s eta 0:00:03\n","   --------------------------------- ----- 170.1/197.9 MB 12.9 MB/s eta 0:00:03\n","   ---------------------------------- ---- 172.8/197.9 MB 12.9 MB/s eta 0:00:02\n","   ---------------------------------- ---- 175.6/197.9 MB 12.9 MB/s eta 0:00:02\n","   ----------------------------------- --- 178.3/197.9 MB 12.9 MB/s eta 0:00:02\n","   ----------------------------------- --- 180.9/197.9 MB 12.9 MB/s eta 0:00:02\n","   ------------------------------------ -- 183.8/197.9 MB 12.9 MB/s eta 0:00:02\n","   ------------------------------------ -- 186.4/197.9 MB 12.9 MB/s eta 0:00:01\n","   ------------------------------------- - 189.0/197.9 MB 12.9 MB/s eta 0:00:01\n","   ------------------------------------- - 191.9/197.9 MB 12.9 MB/s eta 0:00:01\n","   --------------------------------------  194.5/197.9 MB 12.9 MB/s eta 0:00:01\n","   --------------------------------------  197.1/197.9 MB 12.9 MB/s eta 0:00:01\n","   --------------------------------------  197.7/197.9 MB 12.9 MB/s eta 0:00:01\n","   --------------------------------------- 197.9/197.9 MB 12.7 MB/s eta 0:00:00\n","Downloading torchvision-0.19.0-1-cp310-cp310-win_amd64.whl (1.3 MB)\n","   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n","   ---------------------------------------- 1.3/1.3 MB 13.2 MB/s eta 0:00:00\n","Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n","Using cached ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n","Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n","Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n","Downloading contourpy-1.2.1-cp310-cp310-win_amd64.whl (187 kB)\n","Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n","Downloading fonttools-4.53.1-cp310-cp310-win_amd64.whl (2.2 MB)\n","   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n","   ---------------------------------------- 2.2/2.2 MB 12.4 MB/s eta 0:00:00\n","Using cached idna-3.7-py3-none-any.whl (66 kB)\n","Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n","Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n","Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n","Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n","Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n","Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n","Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n","Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n","Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n","Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n","Installing collected packages: pytz, py-cpuinfo, mpmath, urllib3, tzdata, tqdm, sympy, pyyaml, pyparsing, pillow, numpy, networkx, MarkupSafe, kiwisolver, idna, fsspec, fonttools, filelock, cycler, charset-normalizer, certifi, scipy, requests, pandas, opencv-python, jinja2, contourpy, torch, matplotlib, ultralytics-thop, torchvision, seaborn, ultralytics\n","Successfully installed MarkupSafe-2.1.5 certifi-2024.7.4 charset-normalizer-3.3.2 contourpy-1.2.1 cycler-0.12.1 filelock-3.15.4 fonttools-4.53.1 fsspec-2024.6.1 idna-3.7 jinja2-3.1.4 kiwisolver-1.4.5 matplotlib-3.9.1.post1 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 opencv-python-4.10.0.84 pandas-2.2.2 pillow-10.4.0 py-cpuinfo-9.0.0 pyparsing-3.1.2 pytz-2024.1 pyyaml-6.0.2 requests-2.32.3 scipy-1.14.0 seaborn-0.13.2 sympy-1.13.1 torch-2.4.0 torchvision-0.19.0 tqdm-4.66.5 tzdata-2024.1 ultralytics-8.2.74 ultralytics-thop-2.0.0 urllib3-2.2.2\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":1,"id":"c7048f00","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.4.0+cpu\n"]}],"source":["import torch\n","print(torch.__version__) "]},{"cell_type":"code","execution_count":1,"id":"5e27dd71-2b43-48bf-9f05-eba66c1afe50","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5e27dd71-2b43-48bf-9f05-eba66c1afe50","outputId":"d75c6b5e-31b4-41bd-b3ec-327f5556cb64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.73  Python-3.12.4 torch-2.3.0+cpu CPU (AMD Ryzen 5 5600G with Radeon Graphics)\n","\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=100, time=None, patience=100, batch=1, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\train\\labels.cache... 789 images, 0 backgrounds, 0 corrupt: 100%|██████████| 789/789 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\valid\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs\\detect\\train\\labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      1/100         0G      1.078      1.831       1.58          1        640: 100%|██████████| 789/789 [03:19<00:00,  3.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:07<00:00,  4.80it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.598       0.68      0.681      0.461\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      2/100         0G      1.017      1.425      1.548          4        640: 100%|██████████| 789/789 [03:12<00:00,  4.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  6.00it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933       0.84      0.907      0.645\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      3/100         0G      1.045      1.315      1.562          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  5.96it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.764      0.733      0.774      0.539\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      4/100         0G      1.051      1.162      1.563          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.869       0.84      0.858        0.6\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      5/100         0G     0.9838      1.053      1.501          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.836      0.881      0.861      0.619\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      6/100         0G     0.9765      1.031      1.487          4        640: 100%|██████████| 789/789 [03:03<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.738      0.773       0.79      0.522\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      7/100         0G     0.9922      1.058      1.511          2        640: 100%|██████████| 789/789 [03:05<00:00,  4.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.06it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.833      0.827      0.825       0.58\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      8/100         0G      0.926     0.8837      1.437          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.723       0.88      0.833      0.568\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      9/100         0G     0.9247     0.8994       1.45          4        640: 100%|██████████| 789/789 [03:05<00:00,  4.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.917       0.72      0.807      0.612\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     10/100         0G     0.8738     0.8928      1.401          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  5.96it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.719       0.72      0.716      0.509\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     11/100         0G     0.8839     0.7501      1.393          2        640: 100%|██████████| 789/789 [03:08<00:00,  4.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  5.69it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.82      0.733      0.777       0.61\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     12/100         0G     0.8309     0.7391      1.363          2        640: 100%|██████████| 789/789 [03:05<00:00,  4.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.914      0.733      0.865      0.656\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     13/100         0G     0.7977     0.7023      1.328          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.02it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.755       0.84      0.802      0.626\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     14/100         0G     0.7926     0.7203      1.327          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  5.97it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.787      0.872      0.673\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     15/100         0G     0.7619     0.6572      1.327          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.875       0.84       0.86      0.672\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     16/100         0G     0.7569     0.6722      1.309          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.06it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.921      0.667      0.779      0.659\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     17/100         0G     0.7498     0.6823      1.292          1        640: 100%|██████████| 789/789 [03:05<00:00,  4.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.774      0.731      0.694      0.528\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     18/100         0G     0.7668     0.7237      1.336          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.647      0.893      0.815      0.606\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     19/100         0G     0.7217     0.6235      1.278          3        640: 100%|██████████| 789/789 [03:03<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.99      0.613      0.772      0.615\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     20/100         0G       0.73     0.6552      1.276          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.927       0.72      0.836      0.699\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     21/100         0G     0.7042      0.599      1.272          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.986      0.667      0.807      0.618\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     22/100         0G      0.685     0.6126      1.238          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.754       0.84      0.834      0.669\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     23/100         0G     0.6678     0.5739       1.23          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.778      0.787      0.864      0.661\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     24/100         0G     0.6821     0.6633      1.243          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.827      0.773      0.853      0.654\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     25/100         0G      0.679     0.5478      1.255          6        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.01it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.928      0.893      0.896      0.718\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     26/100         0G     0.6497     0.5401      1.208          4        640: 100%|██████████| 789/789 [03:05<00:00,  4.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.823      0.773      0.846      0.652\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     27/100         0G     0.6303     0.5429      1.212          2        640: 100%|██████████| 789/789 [03:05<00:00,  4.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.857      0.773      0.838      0.652\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     28/100         0G     0.6139     0.5365      1.182          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.94      0.838      0.896       0.73\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     29/100         0G     0.6258     0.5358      1.199          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.911       0.72      0.804       0.64\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     30/100         0G     0.6214     0.5357      1.211          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.13it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.798      0.933      0.882      0.722\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     31/100         0G     0.5781     0.5119      1.175          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.925       0.72      0.843      0.695\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     32/100         0G     0.6033     0.5373      1.172          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.877      0.773       0.84      0.707\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     33/100         0G     0.6132     0.5344      1.187          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.925       0.84      0.873      0.712\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     34/100         0G     0.5887     0.4706      1.168          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.825       0.84      0.862      0.682\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     35/100         0G     0.5735     0.4808      1.155          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.848       0.68      0.783      0.661\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     36/100         0G     0.5427     0.4584      1.126          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.793      0.893      0.891      0.692\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     37/100         0G     0.5506     0.4837       1.14          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.879      0.893      0.909      0.704\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     38/100         0G     0.5479     0.4602      1.146          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.14it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.776      0.787      0.861      0.704\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     39/100         0G     0.5357     0.4472      1.129          4        640: 100%|██████████| 789/789 [03:03<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.00it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.918      0.627      0.812      0.621\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     40/100         0G     0.5469       0.46       1.14          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  5.93it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.906      0.667      0.818      0.688\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     41/100         0G     0.5262     0.4375      1.119          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.926       0.84      0.923      0.776\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     42/100         0G     0.5244     0.4037      1.124          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.992      0.773      0.911      0.708\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     43/100         0G     0.5039     0.4159      1.115          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.836      0.887      0.918      0.758\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     44/100         0G     0.4841     0.4189      1.088          1        640: 100%|██████████| 789/789 [03:03<00:00,  4.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.936      0.781      0.893      0.724\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     45/100         0G     0.4868     0.4056      1.098          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.826      0.773      0.878      0.705\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     46/100         0G     0.4795     0.4199      1.081          4        640: 100%|██████████| 789/789 [03:05<00:00,  4.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.88      0.882       0.92      0.627\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     47/100         0G     0.4917     0.4268      1.094          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.88      0.781      0.887       0.73\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     48/100         0G     0.4845     0.4317      1.085          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.13it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.859      0.733      0.811       0.67\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     49/100         0G     0.4748     0.4241      1.083          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.884      0.827      0.866       0.67\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     50/100         0G     0.4672     0.3974      1.083          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.877      0.852      0.912      0.736\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     51/100         0G     0.4695      0.408      1.089          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.874      0.741      0.882      0.704\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     52/100         0G     0.4718     0.3972      1.078          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75          1      0.613        0.8      0.644\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     53/100         0G     0.4445     0.3731      1.064          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.868       0.84        0.9      0.684\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     54/100         0G      0.453     0.3761      1.071          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.01it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.918      0.743       0.84      0.689\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     55/100         0G     0.4421     0.3753      1.051          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.12it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.929       0.72      0.846      0.711\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     56/100         0G     0.4334     0.3636      1.064          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.862      0.787      0.826      0.705\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     57/100         0G     0.4338     0.3788      1.053          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.02it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.87       0.84      0.886      0.726\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     58/100         0G     0.4279     0.3596      1.052          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.924       0.84      0.911      0.752\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     59/100         0G     0.4326     0.3656      1.046          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.916      0.733      0.866      0.691\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     60/100         0G     0.4271     0.3496       1.05          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  5.99it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.847      0.893      0.906      0.725\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     61/100         0G     0.4171     0.3582      1.033          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.937        0.8      0.885      0.705\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     62/100         0G     0.4239     0.3487       1.05          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.882        0.8      0.896      0.728\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     63/100         0G     0.4154      0.363      1.043          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.06it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.916       0.72      0.873      0.717\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     64/100         0G     0.4171     0.3417      1.043          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.827      0.886      0.674\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     65/100         0G        0.4     0.3419      1.029          1        640: 100%|██████████| 789/789 [03:05<00:00,  4.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.14it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.881      0.786      0.906      0.739\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     66/100         0G     0.3882     0.3479      1.028          4        640: 100%|██████████| 789/789 [03:05<00:00,  4.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.02it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.888      0.848       0.91      0.747\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     67/100         0G     0.3965     0.3587      1.025          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.14it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.922       0.72       0.86      0.688\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     68/100         0G     0.3889     0.3303       1.03          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.94      0.835      0.937      0.781\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     69/100         0G     0.3971     0.3163      1.029          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.882        0.8      0.917      0.771\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     70/100         0G     0.3783      0.325      1.018          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.936      0.785      0.893      0.773\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     71/100         0G     0.3727     0.3193       1.02          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.937      0.797      0.927      0.745\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     72/100         0G      0.364     0.3342      1.008          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.02it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.876      0.787       0.91      0.704\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     73/100         0G     0.3653     0.3262      1.015          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.17it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.882      0.797      0.918      0.734\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     74/100         0G     0.3639      0.313       1.01          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  5.92it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.743      0.888      0.716\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     75/100         0G     0.3606     0.3236      1.011          2        640: 100%|██████████| 789/789 [03:06<00:00,  4.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.12it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.873      0.734      0.863      0.656\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     76/100         0G     0.3691     0.3014      1.019          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.12it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.884       0.84      0.902      0.703\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     77/100         0G     0.3475     0.2854     0.9927          1        640: 100%|██████████| 789/789 [03:03<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.743       0.88      0.681\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     78/100         0G     0.3574     0.3036      1.001          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.886       0.84      0.864      0.689\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     79/100         0G     0.3349     0.2997     0.9931          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.745      0.865      0.698\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     80/100         0G     0.3523      0.304      1.007          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.12it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.866      0.689      0.889      0.707\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     81/100         0G     0.3351     0.2872     0.9938          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.924       0.72      0.879      0.727\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     82/100         0G     0.3429      0.314     0.9997          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:06<00:00,  6.00it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.866       0.69      0.911      0.728\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     83/100         0G     0.3334     0.2996     0.9913          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.882      0.795      0.932      0.739\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     84/100         0G     0.3313     0.2958     0.9901          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.937      0.797      0.932      0.734\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     85/100         0G     0.3166     0.2847     0.9882          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.892      0.893      0.914      0.686\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     86/100         0G     0.3234     0.2883     0.9851          2        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.841      0.893      0.897      0.684\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     87/100         0G     0.3226     0.2917     0.9818          3        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.881      0.789      0.901      0.674\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     88/100         0G     0.3172     0.2753     0.9814          4        640: 100%|██████████| 789/789 [03:04<00:00,  4.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.06it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.929      0.733      0.843       0.66\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     89/100         0G     0.3109     0.2847     0.9718          3        640: 100%|██████████| 789/789 [03:03<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.924      0.733      0.881      0.686\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     90/100         0G     0.3092     0.2718     0.9864          1        640: 100%|██████████| 789/789 [03:04<00:00,  4.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.14it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.743      0.897      0.685\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Closing dataloader mosaic\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     91/100         0G     0.1962     0.1609     0.9025          1        640: 100%|██████████| 789/789 [03:02<00:00,  4.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.13it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.937      0.798      0.932      0.726\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     92/100         0G     0.1897     0.1514     0.8948          1        640: 100%|██████████| 789/789 [03:02<00:00,  4.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.745      0.948      0.736\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     93/100         0G     0.1787     0.1486     0.8868          1        640: 100%|██████████| 789/789 [03:03<00:00,  4.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.932      0.734      0.938      0.744\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     94/100         0G     0.1727      0.147     0.8841          1        640: 100%|██████████| 789/789 [03:02<00:00,  4.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.932      0.733      0.923      0.731\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     95/100         0G     0.1566     0.1353     0.8767          1        640: 100%|██████████| 789/789 [03:02<00:00,  4.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.932       0.73      0.897      0.744\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     96/100         0G     0.1607     0.1352     0.8825          1        640: 100%|██████████| 789/789 [03:02<00:00,  4.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.932      0.732      0.913       0.76\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     97/100         0G     0.1512     0.1297     0.8731          1        640: 100%|██████████| 789/789 [03:03<00:00,  4.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.746      0.927      0.765\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     98/100         0G     0.1474     0.1278     0.8682          2        640: 100%|██████████| 789/789 [03:02<00:00,  4.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.06it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.742      0.927      0.769\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     99/100         0G     0.1445     0.1282     0.8776          1        640: 100%|██████████| 789/789 [03:02<00:00,  4.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933      0.739      0.929      0.768\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["    100/100         0G     0.1439     0.1263     0.8575          1        640: 100%|██████████| 789/789 [03:03<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:05<00:00,  6.11it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75      0.933       0.74      0.932      0.757\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","100 epochs completed in 5.303 hours.\n","Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.3MB\n","Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.3MB\n","\n","Validating runs\\detect\\train\\weights\\best.pt...\n","Ultralytics YOLOv8.2.73  Python-3.12.4 torch-2.3.0+cpu CPU (AMD Ryzen 5 5600G with Radeon Graphics)\n","Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:04<00:00,  7.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.94      0.835      0.937      0.781\n","Speed: 1.2ms preprocess, 58.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n","Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"]}],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n","\n","# Train the model with CPU\n","results = model.train(data='data.yaml', epochs=100, imgsz=640, batch=1, device = 'cpu')"]},{"cell_type":"code","execution_count":3,"id":"d5bf496c-65c0-4bc8-b076-e626ad5d87cf","metadata":{"id":"d5bf496c-65c0-4bc8-b076-e626ad5d87cf","outputId":"95eea4e9-392d-479c-f95e-305feacb1bd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.73  Python-3.12.4 torch-2.3.0+cpu CPU (AMD Ryzen 5 5600G with Radeon Graphics)\n","Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\valid\\labels.cache... 71 images, 0 backgrounds, 0 corrupt: 100%|██████████| 71/71 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n"]},{"name":"stdout","output_type":"stream","text":["                   all         71         75       0.94      0.835      0.937      0.781\n","Speed: 1.9ms preprocess, 61.5ms inference, 0.0ms loss, 0.2ms postprocess per image\n","Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"]},{"data":{"text/plain":["array([    0.78095])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Validate model\n","\n","from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('runs/detect/train/weights/best.pt')  # load a custom model\n","\n","# Validate the model\n","metrics = model.val()  # no arguments needed, dataset and settings remembered\n","metrics.box.map    # map50-95\n","metrics.box.map50  # map50\n","metrics.box.map75  # map75\n","metrics.box.maps   # a list contains map50-95 of each category"]},{"cell_type":"code","execution_count":5,"id":"28af2e54-9d78-4da5-8fa7-137344fcfd3f","metadata":{"id":"28af2e54-9d78-4da5-8fa7-137344fcfd3f","outputId":"90c65d17-431f-4db5-d3d3-45c681680447"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.02105cc88f4f56199c90a9b0924ac3fa.jpg: 640x640 1 tv, 80.8ms\n","image 2/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.913750077d8f0eec5ee7d9914061ff19.jpg: 640x640 1 tv, 65.3ms\n","image 3/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.92ceb501f025369bdf92cc4c2feb2678.jpg: 640x640 1 tv, 63.7ms\n","image 4/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.c32e63eba0631f73c5562102eef735f5.jpg: 640x640 1 tv, 62.2ms\n","image 5/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.4c5fe257d07bb273a0aa4e972efd28e8.jpg: 640x640 1 tv, 59.5ms\n","image 6/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.9bca726a0778d68a58932f3b18318996.jpg: 640x640 1 tv, 73.4ms\n","image 7/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.9f68b77b152971b99a77599d2d0c3be3.jpg: 640x640 1 tv, 61.9ms\n","image 8/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.bf020938ff5727f03506dc7b825112e3.jpg: 640x640 1 tv, 59.5ms\n","image 9/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.137179c98b11b97baa28685a959a6c64.jpg: 640x640 1 tv, 60.9ms\n","image 10/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.45f7f7b3d63d195324f5b9a356bf8693.jpg: 640x640 1 tv, 60.4ms\n","image 11/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.5acdb9ae57904bd2fb2ec23697705fb9.jpg: 640x640 1 tv, 60.5ms\n","image 12/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.f26ee8a5f5ac3e3e837211ad437e7441.jpg: 640x640 1 tv, 61.4ms\n","image 13/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.01ece95651138d4ce3289106a51754ec.jpg: 640x640 1 tv, 63.8ms\n","image 14/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.51130c259309d809247a05c6bdb783cc.jpg: 640x640 1 tv, 61.7ms\n","image 15/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.a9ba764c4c4d47c9c87bd21574d8e83d.jpg: 640x640 1 tv, 63.0ms\n","image 16/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.b219b0bb2f6c06360bf5ff7c21be848d.jpg: 640x640 1 tv, 64.2ms\n","image 17/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.3e8120cdeeb9962c938b43565bc2ce56.jpg: 640x640 1 tv, 66.9ms\n","image 18/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.4ec1e5845648bfe023e1cdd514db012d.jpg: 640x640 1 tv, 61.8ms\n","image 19/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.7324ea73e7e1c538651f1b6516fc991a.jpg: 640x640 1 tv, 60.3ms\n","image 20/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.fc177baf0bdf140805792cc3b7d22995.jpg: 640x640 1 tv, 53.6ms\n","image 21/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.527a9086d344fdd39b0f152e39ce29cb.jpg: 640x640 1 tv, 61.9ms\n","image 22/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.6652abcc59825b2fe58671b6c93f8a0d.jpg: 640x640 1 tv, 61.0ms\n","image 23/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.7cebada917e22748c6dcc8472597710c.jpg: 640x640 1 tv, 62.1ms\n","image 24/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.c75091f00d20fe9c87f4bebcd9c288d0.jpg: 640x640 1 tv, 63.4ms\n","image 25/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.0df85a59733cfb8ab071af9a97a811c4.jpg: 640x640 (no detections), 62.1ms\n","image 26/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.420aad9e81c8e4601efefd141082ca30.jpg: 640x640 (no detections), 65.2ms\n","image 27/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.b5f2b3b2bf7d0af43f5ff20ed8321c14.jpg: 640x640 (no detections), 62.5ms\n","image 28/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.c5f7db0250549378fd675a378c8271d1.jpg: 640x640 (no detections), 61.2ms\n","image 29/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.06e87aac8828b96f583454bc0ebe7800.jpg: 640x640 1 tv, 60.6ms\n","image 30/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.202343995db6bdf655e0cacfdc431700.jpg: 640x640 1 tv, 59.6ms\n","image 31/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.a322c20b2ca6efbfe6925bb17df1f526.jpg: 640x640 1 tv, 52.1ms\n","image 32/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.ed93a7061ac032288e2dbf6a61b5e329.jpg: 640x640 1 tv, 64.1ms\n","image 33/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.240231f3539104914413af47ecd1e1b3.jpg: 640x640 1 tv, 67.2ms\n","image 34/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.459a086184dbf058e83a6fd1799adf88.jpg: 640x640 1 tv, 67.4ms\n","image 35/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.63a46178432f8d5104dc3afb07fd10cd.jpg: 640x640 1 tv, 62.1ms\n","image 36/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.98c84486f432a6ec876caae985ec74ef.jpg: 640x640 1 tv, 63.7ms\n","Speed: 1.6ms preprocess, 62.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"]},{"data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.02105cc88f4f56199c90a9b0924ac3fa.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 80.7962417602539, 'postprocess': 0.79345703125},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.913750077d8f0eec5ee7d9914061ff19.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.9999275207519531, 'inference': 65.25158882141113, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.92ceb501f025369bdf92cc4c2feb2678.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 63.67850303649902, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.c32e63eba0631f73c5562102eef735f5.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 2.0122528076171875, 'inference': 62.23654747009277, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.4c5fe257d07bb273a0aa4e972efd28e8.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 1.3706684112548828, 'inference': 59.456825256347656, 'postprocess': 0.99945068359375},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.9bca726a0778d68a58932f3b18318996.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 73.41241836547852, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.9f68b77b152971b99a77599d2d0c3be3.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 61.873435974121094, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.bf020938ff5727f03506dc7b825112e3.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 59.53240394592285, 'postprocess': 2.0148754119873047},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.137179c98b11b97baa28685a959a6c64.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 8.013248443603516, 'inference': 60.8980655670166, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.45f7f7b3d63d195324f5b9a356bf8693.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 4.517555236816406, 'inference': 60.35017967224121, 'postprocess': 1.0001659393310547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.5acdb9ae57904bd2fb2ec23697705fb9.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.5352497100830078, 'inference': 60.534000396728516, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.f26ee8a5f5ac3e3e837211ad437e7441.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 61.38110160827637, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.01ece95651138d4ce3289106a51754ec.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 63.80748748779297, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.51130c259309d809247a05c6bdb783cc.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 61.678409576416016, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.a9ba764c4c4d47c9c87bd21574d8e83d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 62.9582405090332, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.b219b0bb2f6c06360bf5ff7c21be848d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 64.20063972473145, 'postprocess': 4.020452499389648},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.3e8120cdeeb9962c938b43565bc2ce56.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 66.85662269592285, 'postprocess': 1.5227794647216797},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.4ec1e5845648bfe023e1cdd514db012d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 3.5479068756103516, 'inference': 61.81907653808594, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.7324ea73e7e1c538651f1b6516fc991a.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 1.627206802368164, 'inference': 60.347795486450195, 'postprocess': 1.0001659393310547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.fc177baf0bdf140805792cc3b7d22995.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 7.01141357421875, 'inference': 53.615570068359375, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.527a9086d344fdd39b0f152e39ce29cb.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 61.94353103637695, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.6652abcc59825b2fe58671b6c93f8a0d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 61.005353927612305, 'postprocess': 1.0001659393310547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.7cebada917e22748c6dcc8472597710c.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 62.077999114990234, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.c75091f00d20fe9c87f4bebcd9c288d0.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 8.020639419555664, 'inference': 63.3997917175293, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.0df85a59733cfb8ab071af9a97a811c4.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 8.014678955078125, 'inference': 62.109947204589844, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.420aad9e81c8e4601efefd141082ca30.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 65.19675254821777, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.b5f2b3b2bf7d0af43f5ff20ed8321c14.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 62.471628189086914, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.c5f7db0250549378fd675a378c8271d1.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 61.22875213623047, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.06e87aac8828b96f583454bc0ebe7800.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 2.009868621826172, 'inference': 60.59861183166504, 'postprocess': 1.0001659393310547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.202343995db6bdf655e0cacfdc431700.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.5114078521728516, 'inference': 59.64994430541992, 'postprocess': 1.0001659393310547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.a322c20b2ca6efbfe6925bb17df1f526.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 8.046627044677734, 'inference': 52.14715003967285, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.ed93a7061ac032288e2dbf6a61b5e329.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 64.1469955444336, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.240231f3539104914413af47ecd1e1b3.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 67.19136238098145, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.459a086184dbf058e83a6fd1799adf88.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 67.39282608032227, 'postprocess': 2.016305923461914},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.63a46178432f8d5104dc3afb07fd10cd.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 2.012014389038086, 'inference': 62.09421157836914, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.98c84486f432a6ec876caae985ec74ef.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict'\n"," speed: {'preprocess': 0.0, 'inference': 63.71760368347168, 'postprocess': 0.0}]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#  Prediction using trained model\n","\n","from ultralytics import YOLO\n","\n","# Load a pretrained YOLOv8n model\n","model = YOLO('runs/detect/train/weights/best.pt')\n","\n","# Run inference\n","model.predict('DatasetV8/test/images', save=True, imgsz=640, conf=0.2)"]},{"cell_type":"code","execution_count":1,"id":"5c666b24","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Package                      Version\n","---------------------------- -----------\n","absl-py                      2.1.0\n","asttokens                    2.4.1\n","astunparse                   1.6.3\n","cachetools                   5.4.0\n","certifi                      2024.7.4\n","charset-normalizer           3.3.2\n","colorama                     0.4.6\n","coloredlogs                  15.0.1\n","comm                         0.2.2\n","contourpy                    1.2.1\n","cycler                       0.12.1\n","debugpy                      1.8.5\n","decorator                    5.1.1\n","exceptiongroup               1.2.2\n","executing                    2.0.1\n","filelock                     3.15.4\n","flatbuffers                  24.3.25\n","fonttools                    4.53.1\n","fsspec                       2024.6.1\n","gast                         0.4.0\n","google-auth                  2.33.0\n","google-auth-oauthlib         1.0.0\n","google-pasta                 0.2.0\n","grpcio                       1.65.4\n","h5py                         3.11.0\n","humanfriendly                10.0\n","idna                         3.7\n","ipykernel                    6.29.5\n","ipython                      8.26.0\n","jax                          0.4.30\n","jaxlib                       0.4.30\n","jedi                         0.19.1\n","Jinja2                       3.1.4\n","jupyter_client               8.6.2\n","jupyter_core                 5.7.2\n","keras                        3.4.1\n","kiwisolver                   1.4.5\n","libclang                     18.1.1\n","Markdown                     3.6\n","markdown-it-py               3.0.0\n","MarkupSafe                   2.1.5\n","matplotlib                   3.9.1.post1\n","matplotlib-inline            0.1.7\n","mdurl                        0.1.2\n","ml-dtypes                    0.3.2\n","mpmath                       1.3.0\n","namex                        0.0.8\n","nest-asyncio                 1.6.0\n","networkx                     3.3\n","numpy                        1.23.5\n","oauthlib                     3.2.2\n","onnx                         1.16.2\n","onnx-graphsurgeon            0.5.2\n","onnx2tf                      1.22.3\n","onnxruntime                  1.18.1\n","onnxslim                     0.1.32\n","opencv-python                4.10.0.84\n","opt-einsum                   3.3.0\n","optree                       0.12.1\n","packaging                    24.1\n","pandas                       2.2.2\n","parso                        0.8.4\n","pillow                       10.4.0\n","pip                          24.2\n","platformdirs                 4.2.2\n","prompt_toolkit               3.0.47\n","protobuf                     4.25.4\n","psutil                       6.0.0\n","pure_eval                    0.2.3\n","py-cpuinfo                   9.0.0\n","pyasn1                       0.6.0\n","pyasn1_modules               0.4.0\n","pybind11                     2.13.1\n","Pygments                     2.18.0\n","pyparsing                    3.1.2\n","pyreadline3                  3.4.1\n","python-dateutil              2.9.0.post0\n","pytz                         2024.1\n","pywin32                      306\n","PyYAML                       6.0.2\n","pyzmq                        26.1.0\n","requests                     2.32.3\n","requests-oauthlib            2.0.0\n","rich                         13.7.1\n","rsa                          4.9\n","scipy                        1.14.0\n","seaborn                      0.13.2\n","setuptools                   65.5.0\n","six                          1.16.0\n","sng4onnx                     1.0.4\n","stack-data                   0.6.3\n","sympy                        1.13.1\n","tensorboard                  2.16.2\n","tensorboard-data-server      0.7.2\n","tensorflow                   2.16.2\n","tensorflow-cpu               2.12.0\n","tensorflow-estimator         2.12.0\n","tensorflow-intel             2.16.2\n","tensorflow-io-gcs-filesystem 0.31.0\n","termcolor                    2.4.0\n","tf_keras                     2.16.0\n","tflite-support               0.1.0a1\n","torch                        2.4.0\n","torchvision                  0.19.0\n","tornado                      6.4.1\n","tqdm                         4.66.5\n","traitlets                    5.14.3\n","typing_extensions            4.12.2\n","tzdata                       2024.1\n","ultralytics-thop             2.0.0\n","urllib3                      2.2.2\n","wcwidth                      0.2.13\n","Werkzeug                     3.0.3\n","wheel                        0.44.0\n","wrapt                        1.14.1\n"]}],"source":["!pip list"]},{"cell_type":"code","execution_count":2,"id":"2f3d815e-d7ad-4f2d-b540-b3039f1230e1","metadata":{"id":"2f3d815e-d7ad-4f2d-b540-b3039f1230e1","outputId":"6397a2bb-3629-4ed9-810a-e683337d33bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.74  Python-3.10.11 torch-2.4.0+cpu CPU (AMD Ryzen 5 5600G with Radeon Graphics)\n","Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.16.2...\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.32...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.3s, saved as 'runs\\detect\\train\\weights\\best.onnx' (11.8 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  14.6s, saved as 'runs\\detect\\train\\weights\\best_saved_model' (29.5 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.16.2...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success  0.0s, saved as 'runs\\detect\\train\\weights\\best_saved_model\\best_float32.tflite' (11.7 MB)\n","\n","Export complete (16.8s)\n","Results saved to \u001b[1mC:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\runs\\detect\\train\\weights\u001b[0m\n","Predict:         yolo predict task=detect model=runs\\detect\\train\\weights\\best_saved_model\\best_float32.tflite imgsz=640  \n","Validate:        yolo val task=detect model=runs\\detect\\train\\weights\\best_saved_model\\best_float32.tflite imgsz=640 data=data.yaml  \n","Visualize:       https://netron.app\n"]},{"data":{"text/plain":["'runs\\\\detect\\\\train\\\\weights\\\\best_saved_model\\\\best_float32.tflite'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#  Export model to tflite\n","\n","\n","from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('runs/detect/train/weights/best.pt')  # load a custom trained model\n","\n","# Export the model\n","model.export(format='tflite')"]},{"cell_type":"code","execution_count":6,"id":"b3aae33b-b14a-43f6-861f-3e0f2d21407f","metadata":{"id":"b3aae33b-b14a-43f6-861f-3e0f2d21407f","outputId":"6f1a279d-ac34-4f46-820d-b027bc50c724"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading runs\\detect\\train\\weights\\best_saved_model\\best_float32.tflite for TensorFlow Lite inference...\n","\n","image 1/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.02105cc88f4f56199c90a9b0924ac3fa.jpg: 640x640 1 tv, 97.9ms\n","image 2/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.913750077d8f0eec5ee7d9914061ff19.jpg: 640x640 1 tv, 84.6ms\n","image 3/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.92ceb501f025369bdf92cc4c2feb2678.jpg: 640x640 1 tv, 86.1ms\n","image 4/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\download-19-_jpg.rf.c32e63eba0631f73c5562102eef735f5.jpg: 640x640 1 tv, 86.0ms\n","image 5/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.4c5fe257d07bb273a0aa4e972efd28e8.jpg: 640x640 1 tv, 99.7ms\n","image 6/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.9bca726a0778d68a58932f3b18318996.jpg: 640x640 1 tv, 84.4ms\n","image 7/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.9f68b77b152971b99a77599d2d0c3be3.jpg: 640x640 1 tv, 86.0ms\n","image 8/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-1-_jpg.rf.bf020938ff5727f03506dc7b825112e3.jpg: 640x640 1 tv, 86.2ms\n","image 9/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.137179c98b11b97baa28685a959a6c64.jpg: 640x640 1 tv, 80.9ms\n","image 10/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.45f7f7b3d63d195324f5b9a356bf8693.jpg: 640x640 1 tv, 84.0ms\n","image 11/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.5acdb9ae57904bd2fb2ec23697705fb9.jpg: 640x640 1 tv, 100.7ms\n","image 12/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-11-_jpg.rf.f26ee8a5f5ac3e3e837211ad437e7441.jpg: 640x640 1 tv, 86.4ms\n","image 13/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.01ece95651138d4ce3289106a51754ec.jpg: 640x640 1 tv, 85.9ms\n","image 14/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.51130c259309d809247a05c6bdb783cc.jpg: 640x640 1 tv, 86.1ms\n","image 15/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.a9ba764c4c4d47c9c87bd21574d8e83d.jpg: 640x640 1 tv, 83.2ms\n","image 16/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-13-_jpg.rf.b219b0bb2f6c06360bf5ff7c21be848d.jpg: 640x640 1 tv, 100.0ms\n","image 17/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.3e8120cdeeb9962c938b43565bc2ce56.jpg: 640x640 1 tv, 87.2ms\n","image 18/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.4ec1e5845648bfe023e1cdd514db012d.jpg: 640x640 1 tv, 94.5ms\n","image 19/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.7324ea73e7e1c538651f1b6516fc991a.jpg: 640x640 1 tv, 82.0ms\n","image 20/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-23-_jpg.rf.fc177baf0bdf140805792cc3b7d22995.jpg: 640x640 1 tv, 83.4ms\n","image 21/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.527a9086d344fdd39b0f152e39ce29cb.jpg: 640x640 1 tv, 85.8ms\n","image 22/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.6652abcc59825b2fe58671b6c93f8a0d.jpg: 640x640 1 tv, 85.5ms\n","image 23/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.7cebada917e22748c6dcc8472597710c.jpg: 640x640 1 tv, 86.2ms\n","image 24/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-54-_jpg.rf.c75091f00d20fe9c87f4bebcd9c288d0.jpg: 640x640 1 tv, 85.3ms\n","image 25/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.0df85a59733cfb8ab071af9a97a811c4.jpg: 640x640 (no detections), 86.5ms\n","image 26/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.420aad9e81c8e4601efefd141082ca30.jpg: 640x640 (no detections), 85.4ms\n","image 27/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.b5f2b3b2bf7d0af43f5ff20ed8321c14.jpg: 640x640 (no detections), 107.3ms\n","image 28/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-6-_jpg.rf.c5f7db0250549378fd675a378c8271d1.jpg: 640x640 (no detections), 84.3ms\n","image 29/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.06e87aac8828b96f583454bc0ebe7800.jpg: 640x640 1 tv, 72.5ms\n","image 30/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.202343995db6bdf655e0cacfdc431700.jpg: 640x640 1 tv, 83.9ms\n","image 31/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.a322c20b2ca6efbfe6925bb17df1f526.jpg: 640x640 1 tv, 98.7ms\n","image 32/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-60-_jpg.rf.ed93a7061ac032288e2dbf6a61b5e329.jpg: 640x640 1 tv, 90.3ms\n","image 33/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.240231f3539104914413af47ecd1e1b3.jpg: 640x640 1 tv, 89.7ms\n","image 34/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.459a086184dbf058e83a6fd1799adf88.jpg: 640x640 1 tv, 84.0ms\n","image 35/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.63a46178432f8d5104dc3afb07fd10cd.jpg: 640x640 1 tv, 78.3ms\n","image 36/36 c:\\Users\\Kev9n\\OneDrive\\Documentos\\TV-Screen-Object-Detection\\DatasetV8\\test\\images\\images-71-_jpg.rf.98c84486f432a6ec876caae985ec74ef.jpg: 640x640 1 tv, 92.4ms\n","Speed: 1.6ms preprocess, 87.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"]},{"data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.02105cc88f4f56199c90a9b0924ac3fa.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 97.85223007202148, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.913750077d8f0eec5ee7d9914061ff19.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 15.650749206542969, 'inference': 84.56707000732422, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.92ceb501f025369bdf92cc4c2feb2678.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 86.05408668518066, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        [[184, 186, 186],\n","         [184, 186, 186],\n","         [184, 186, 186],\n","         ...,\n","         [208, 213, 211],\n","         [208, 213, 211],\n","         [208, 213, 211]],\n"," \n","        ...,\n"," \n","        [[119, 145, 127],\n","         [126, 152, 134],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[118, 144, 126],\n","         [125, 151, 133],\n","         [104, 130, 112],\n","         ...,\n","         [104, 154, 100],\n","         [105, 155, 101],\n","         [105, 155, 101]],\n"," \n","        [[123, 149, 131],\n","         [129, 155, 137],\n","         [107, 133, 115],\n","         ...,\n","         [105, 155, 101],\n","         [106, 156, 102],\n","         [107, 157, 103]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\download-19-_jpg.rf.c32e63eba0631f73c5562102eef735f5.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 85.95895767211914, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.4c5fe257d07bb273a0aa4e972efd28e8.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 99.66611862182617, 'postprocess': 0.9992122650146484},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.9bca726a0778d68a58932f3b18318996.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 15.360832214355469, 'inference': 84.42807197570801, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.9f68b77b152971b99a77599d2d0c3be3.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 85.97493171691895, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        [[44, 56, 60],\n","         [43, 55, 59],\n","         [42, 54, 58],\n","         ...,\n","         [71, 87, 94],\n","         [71, 87, 94],\n","         [72, 88, 95]],\n"," \n","        ...,\n"," \n","        [[ 3, 25, 23],\n","         [ 3, 25, 23],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 3, 25, 23],\n","         [ 4, 26, 24],\n","         [ 5, 27, 25],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]],\n"," \n","        [[ 4, 26, 24],\n","         [ 4, 26, 24],\n","         [ 6, 28, 26],\n","         ...,\n","         [15, 28, 12],\n","         [15, 28, 12],\n","         [15, 28, 12]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-1-_jpg.rf.bf020938ff5727f03506dc7b825112e3.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 86.16113662719727, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.137179c98b11b97baa28685a959a6c64.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 80.86657524108887, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.45f7f7b3d63d195324f5b9a356bf8693.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 83.97364616394043, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.5acdb9ae57904bd2fb2ec23697705fb9.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 100.66604614257812, 'postprocess': 1.0001659393310547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [140, 173, 188],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [139, 172, 187],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        [[ 88,  57,  36],\n","         [ 88,  57,  36],\n","         [ 88,  57,  36],\n","         ...,\n","         [137, 170, 185],\n","         [137, 170, 185],\n","         [140, 173, 188]],\n"," \n","        ...,\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]],\n"," \n","        [[ 52,  53,  49],\n","         [ 52,  53,  49],\n","         [ 52,  53,  49],\n","         ...,\n","         [ 45,  50,  48],\n","         [ 45,  50,  48],\n","         [ 45,  50,  48]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-11-_jpg.rf.f26ee8a5f5ac3e3e837211ad437e7441.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 86.4264965057373, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.01ece95651138d4ce3289106a51754ec.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 85.8755111694336, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.51130c259309d809247a05c6bdb783cc.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 86.07721328735352, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.a9ba764c4c4d47c9c87bd21574d8e83d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 83.22858810424805, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        [[253, 253, 253],\n","         [253, 253, 253],\n","         [253, 253, 253],\n","         ...,\n","         [254, 254, 254],\n","         [254, 254, 254],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]],\n"," \n","        [[241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         ...,\n","         [241, 241, 241],\n","         [241, 241, 241],\n","         [241, 241, 241]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-13-_jpg.rf.b219b0bb2f6c06360bf5ff7c21be848d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 100.02756118774414, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.3e8120cdeeb9962c938b43565bc2ce56.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 87.15438842773438, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.4ec1e5845648bfe023e1cdd514db012d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 94.54679489135742, 'postprocess': 0.38933753967285156},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.7324ea73e7e1c538651f1b6516fc991a.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 2.0003318786621094, 'inference': 81.97283744812012, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[252, 252, 252],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [253, 253, 253],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        ...,\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]],\n"," \n","        [[  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         ...,\n","         [  2,   0, 254],\n","         [  2,   0, 254],\n","         [  2,   0, 254]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-23-_jpg.rf.fc177baf0bdf140805792cc3b7d22995.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 83.41622352600098, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.527a9086d344fdd39b0f152e39ce29cb.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 85.78634262084961, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.6652abcc59825b2fe58671b6c93f8a0d.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 85.54840087890625, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.7cebada917e22748c6dcc8472597710c.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 86.17448806762695, 'postprocess': 13.915777206420898},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[193, 214, 229],\n","         [193, 214, 229],\n","         [193, 214, 229],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[192, 213, 228],\n","         [193, 214, 229],\n","         [192, 213, 228],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        [[194, 215, 230],\n","         [195, 216, 231],\n","         [194, 215, 230],\n","         ...,\n","         [142, 157, 173],\n","         [142, 157, 173],\n","         [142, 157, 173]],\n"," \n","        ...,\n"," \n","        [[162, 195, 210],\n","         [162, 195, 210],\n","         [162, 195, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]],\n"," \n","        [[161, 196, 210],\n","         [161, 196, 210],\n","         [161, 196, 210],\n","         ...,\n","         [121, 146, 172],\n","         [121, 146, 172],\n","         [121, 146, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-54-_jpg.rf.c75091f00d20fe9c87f4bebcd9c288d0.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 2.000093460083008, 'inference': 85.29376983642578, 'postprocess': 0.7903575897216797},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.0df85a59733cfb8ab071af9a97a811c4.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 3.197908401489258, 'inference': 86.49373054504395, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.420aad9e81c8e4601efefd141082ca30.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 3.917217254638672, 'inference': 85.40701866149902, 'postprocess': 1.0006427764892578},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.b5f2b3b2bf7d0af43f5ff20ed8321c14.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 107.28883743286133, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[ 55,  54,  50],\n","         [ 55,  54,  50],\n","         [ 57,  56,  52],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 56,  55,  51],\n","         [ 57,  56,  52],\n","         [ 58,  57,  53],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        [[ 58,  57,  53],\n","         [ 58,  57,  53],\n","         [ 59,  58,  54],\n","         ...,\n","         [191, 167, 125],\n","         [189, 167, 125],\n","         [188, 166, 124]],\n"," \n","        ...,\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 22,  25,  23],\n","         [ 21,  24,  22]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 23,  26,  24],\n","         [ 23,  26,  24]],\n"," \n","        [[ 62,  90, 121],\n","         [ 62,  90, 121],\n","         [ 62,  90, 121],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 24,  27,  25],\n","         [ 24,  27,  25]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-6-_jpg.rf.c5f7db0250549378fd675a378c8271d1.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 3.001689910888672, 'inference': 84.33675765991211, 'postprocess': 1.0001659393310547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.06e87aac8828b96f583454bc0ebe7800.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 3.0007362365722656, 'inference': 72.54171371459961, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.202343995db6bdf655e0cacfdc431700.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 83.85848999023438, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.a322c20b2ca6efbfe6925bb17df1f526.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 98.66070747375488, 'postprocess': 1.0023117065429688},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[254, 254, 254],\n","         [254, 254, 254],\n","         [251, 251, 251],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        [[254, 254, 254],\n","         [254, 254, 254],\n","         [252, 252, 252],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [254, 254, 254]],\n"," \n","        ...,\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]],\n"," \n","        [[255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         ...,\n","         [255, 255, 255],\n","         [255, 255, 255],\n","         [255, 255, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-60-_jpg.rf.ed93a7061ac032288e2dbf6a61b5e329.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 4.001617431640625, 'inference': 90.31176567077637, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.240231f3539104914413af47ecd1e1b3.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 1.4269351959228516, 'inference': 89.73097801208496, 'postprocess': 0.9999275207519531},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.459a086184dbf058e83a6fd1799adf88.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 2.4995803833007812, 'inference': 83.96315574645996, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.63a46178432f8d5104dc3afb07fd10cd.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 3.000974655151367, 'inference': 78.33695411682129, 'postprocess': 0.0},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'tv'}\n"," obb: None\n"," orig_img: array([[[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        [[229, 240, 248],\n","         [229, 240, 248],\n","         [229, 240, 248],\n","         ...,\n","         [150, 176, 192],\n","         [150, 176, 192],\n","         [150, 176, 192]],\n"," \n","        ...,\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]],\n"," \n","        [[230, 235, 244],\n","         [230, 235, 244],\n","         [230, 235, 244],\n","         ...,\n","         [167, 176, 185],\n","         [167, 176, 185],\n","         [167, 176, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: 'c:\\\\Users\\\\Kev9n\\\\OneDrive\\\\Documentos\\\\TV-Screen-Object-Detection\\\\DatasetV8\\\\test\\\\images\\\\images-71-_jpg.rf.98c84486f432a6ec876caae985ec74ef.jpg'\n"," probs: None\n"," save_dir: 'runs\\\\detect\\\\predict2'\n"," speed: {'preprocess': 0.0, 'inference': 92.38743782043457, 'postprocess': 0.0}]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Prediction using custom tflite model\n","\n","#  Prediction using trained model\n","\n","from ultralytics import YOLO\n","\n","# Load a pretrained YOLOv8n model\n","model = YOLO('runs/detect/train/weights/best_saved_model/best_float32.tflite')\n","\n","# Run inference\n","model.predict('DatasetV8/test/images', save=True, imgsz=640, conf=0.2)"]},{"cell_type":"code","execution_count":null,"id":"6340d01d-6c54-4989-9f04-91206888e37a","metadata":{"id":"6340d01d-6c54-4989-9f04-91206888e37a"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":5}
